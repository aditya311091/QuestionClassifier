{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function for extracting wh-word feature from the question\n",
    "def wh_word(sent):\n",
    "    whPattern = re.compile(r'(who|what|when|^is|^are|^was|^were)', re.IGNORECASE)\n",
    "    whMatch = whPattern.search(sent)\n",
    "    if whMatch:\n",
    "        whWord = whMatch.group()\n",
    "        if whWord in ['is','Is','are','Are','was','Was','Were','were']:\n",
    "            return 'affirmation'\n",
    "        else:\n",
    "            return str(whWord).lower()\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for loading data from text file and storing in a pandas dataframe along with the wh_word feature\n",
    "def load_file1(f):\n",
    "    f = open(f,'r')\n",
    "    res = []\n",
    "    for line in f:\n",
    "        label, question = line.split(\" \", 1)\n",
    "        res.append((label, question))\n",
    "    df = pd.DataFrame(res, columns= ['label','question'])\n",
    "    LE = LabelEncoder()\n",
    "    df['whword'] = LE1.fit_transform(map(wh_word,df['question']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for loading data from file downloaded from UIUC website and storing in a pandas dataframe along with the wh_word feature\n",
    "def load_file(f):\n",
    "    f = open(f,'r')\n",
    "    res = []\n",
    "    for line in f:\n",
    "        label, question = line.split(\" \", 1)\n",
    "        #\"\"\"\n",
    "        if re.compile(r'date').search(label):\n",
    "            label = 'when'\n",
    "        elif re.compile(r'HUM').search(label):\n",
    "            label = 'who'\n",
    "        elif re.compile(r'ABBR|ENTY|DESC').search(label):\n",
    "            label = 'what'\n",
    "        else:\n",
    "            label = 'Unknown'\n",
    "        #\"\"\"\n",
    "        res.append((label, question))\n",
    "    df = pd.DataFrame(res, columns= ['label','question'])\n",
    "    LE = LabelEncoder()\n",
    "    df['whword'] = LE1.fit_transform(map(wh_word,df['question']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = load_file('train_1000.label') #for loading data from UIUC website\n",
    "#df = load_file1('filename') #for loading data from a text file\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('whword', None),\n",
    "    ('question',CountVectorizer(decode_error=u'ignore', ngram_range=(1, 2), analyzer=u'word', max_df=0.8, min_df=0.002))\n",
    "])\n",
    "\n",
    "X_train = mapper.fit_transform(train)\n",
    "X_test = mapper.transform(test)\n",
    "\n",
    "LE2 = LabelEncoder()\n",
    "y_train = LE2.fit_transform(train['label'])\n",
    "y_test = LE2.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(C = 0.9).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.9, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86387434554973819"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
